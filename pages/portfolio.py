import PyPDF2, pptx, re, io, boto3, base64
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.docstore.document import Document
from langchain.prompts import PromptTemplate
from langchain.chains.summarize import load_summarize_chain
from pptx.enum.shapes import MSO_SHAPE_TYPE
import streamlit as st
from pages.chatbot import init_conversationchain

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” Default ê°’
if "TEMPERATURE" not in st.session_state:
    st.session_state.TEMPERATURE = 0.8
if "TOP_P" not in st.session_state:
    st.session_state.TOP_P = 1.0
if "TOP_K" not in st.session_state:
    st.session_state.TOP_K = 500
if "MAX_TOKENS" not in st.session_state:
    st.session_state.MAX_TOKENS = 4096
if "MEMORY_WINDOW" not in st.session_state:
    st.session_state.MEMORY_WINDOW = 10


def get_portfolio(texts, llm, sections):
    # check korean
    pattern_hangul = re.compile('[\u3131-\u3163\uac00-\ud7a3]+') 
    word_kor = pattern_hangul.search(str(texts))

    if word_kor:
        prompt_template = f"""\n\nHuman: ë‹¤ìŒ íŒŒì¼ì„ ë¶„ì„í•´ì„œ í”„ë¡œì íŠ¸ ë³´ê³ ì„œ í˜•ì‹ìœ¼ë¡œ ì „í™˜í•´ì£¼ì„¸ìš”. ({', '.join(sections)}) ìœ¼ë¡œ ì •ë¦¬í•´ì¤˜. ë§Œì•½ í•´ë‹¹ ë¶€ë¶„ì´ ì—†ë‹¤ë©´ ìƒˆë¡œ ìƒì„±í•´ì¤˜:

        {{text}}

        Assistant:"""        
    else:         
        prompt_template = f"""\n\nHuman: Please analyze the following files and convert it into a project report format with the following sections: ({', '.join(sections)}). If any section is missing, please create it.

        {{text}}

        Assistant:"""

    PROMPT = PromptTemplate(template=prompt_template, input_variables=["text"])

    chain = load_summarize_chain(llm, chain_type="stuff", prompt=PROMPT)

    docs = [
        Document(
            page_content=t
        ) for t in texts[:3]
    ]
    summary = chain.invoke(docs)
    print('\n' + summary['output_text'])
    if summary == '':  # error notification
        summary = 'Fail to analysis the document. Try again...'
        return summary
    else:
        return summary


def portfolio():
    # íŒŒì¼ ì—…ë¡œë“œ ë˜ëŠ” í…ìŠ¤íŠ¸ ì…ë ¥
    upload_or_text = st.radio("í…ìŠ¤íŠ¸ ì…ë ¥ ë˜ëŠ” íŒŒì¼ ì—…ë¡œë“œ", ["í…ìŠ¤íŠ¸ ì…ë ¥", "íŒŒì¼ ì—…ë¡œë“œ"])
    text = None  # text ë³€ìˆ˜ë¥¼ Noneìœ¼ë¡œ ì´ˆê¸°í™”

    # ê¸°ë³¸ ì„¹ì…˜ ì„¤ì •
    all_sections = ["ì œëª©", "ê°œìš”", "ë°°ê²½", "ë§¡ì€ ì—­í• ", "ê²°ê³¼", "ê²°ë¡ ", "í–¥í›„ ê³„íš"]

    default_sections = ["ì œëª©", "ê°œìš”", "ë°°ê²½", "ë§¡ì€ ì—­í• ", "ê²°ê³¼"]
    
    sections = st.multiselect("ë³´ê³ ì„œ ì„¹ì…˜ì„ ì„ íƒí•˜ì„¸ìš”", all_sections, default_sections)

    # ì¤‘ë³µ ì œê±°
    sections = list(set(sections))
    
    if upload_or_text == "í…ìŠ¤íŠ¸ ì…ë ¥":
        text_input = st.text_area("í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”", height=200)
        if st.button("ë¶„ì„ ì‹œì‘"):
            text = text_input

    elif upload_or_text == "íŒŒì¼ ì—…ë¡œë“œ":
        uploaded_file = st.file_uploader("PDF, í…ìŠ¤íŠ¸ ë˜ëŠ” PowerPoint íŒŒì¼ì„ ì„ íƒí•˜ì„¸ìš”", type=["pdf", "txt", "ppt", "pptx"])

        if uploaded_file is not None:
            try:
                if uploaded_file.name.endswith(".pdf"):
                    pdf_reader = PyPDF2.PdfReader(uploaded_file)
                    text = ""
                    for page in range(len(pdf_reader.pages)):
                        text += pdf_reader.pages[page].extract_text()
                elif uploaded_file.name.endswith((".ppt", ".pptx")):
                    presentation = pptx.Presentation(uploaded_file)
                    text = []
                    for slide in presentation.slides:
                        slide_text = []
                        for shape in slide.shapes:
                            if hasattr(shape, "text") and shape.text:
                                slide_text.append(shape.text)
                        text.append("\n".join(slide_text))
                    text = "\n\n".join(text)
                else:
                    text = uploaded_file.read().decode("utf-8")
            except Exception as e:
                st.error(f"íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {str(e)}")
                return


    if text:
        text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)
        texts = text_splitter.split_text(text)

        summary = get_portfolio(texts, st.session_state.llm, sections)
        st.write(summary['output_text'])

if __name__ == "__main__":
    # ëŒ€í™” ì²´ì¸ ì´ˆê¸°í™”, llm ê°ì²´ë¥¼ session_stateì— ì €ì¥
    conv_chain, llm = init_conversationchain()
    st.session_state.llm = llm

    st.set_page_config(page_title='ğŸ“ ë¬¸ì„œ ì •ë¦¬', layout='wide')
    st.title("ğŸ“ í¬íŠ¸í´ë¦¬ì˜¤ ì •ë¦¬")

    portfolio()
